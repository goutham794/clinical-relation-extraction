program: sweep_script_ner_multilingual.py
method: bayes
metric:
  name: f1_score
  goal: maximize
parameters:
  learning_rate:
    min: 0.00001
    max: 0.0001
  batch_size:
    values:
      - 8
      - 16
      - 32
  num_train_epochs:
    values:
      - 4
      - 5
      - 6
  optimizer:
    values:
      - AdamW
      - Adam
  weight_decay:
    min: 0.05
    max: 0.1
  warmup_ratio:
    values:
    - 0.05
    - 0.1
  max_grad_norm:
    values: 
    - 1.0
    - 2.0
  scheduler:
    values:
      - linear_schedule_with_warmup
      - cosine_schedule_with_warmup
      - constant_schedule
      - polynomial_decay_schedule_with_warmup